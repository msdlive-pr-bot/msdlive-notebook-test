{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2868915f-734d-4c8f-a3cb-368c2a674c86",
   "metadata": {},
   "source": [
    "# Explore Weather Data from BSEC Weather Stations\n",
    "\n",
    "Welcome! This notebook will demonstrate how to use the MSD-LIVE data exploration service to visualize, transform, and download a subset of data collected from weather stations around the Baltimore area.\n",
    "\n",
    "You can find the original dataset record at [https://doi.org/10.57931/2476281](https://doi.org/10.57931/2476281).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e52864-dba3-4f67-98f6-cb8c6a4a29a4",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "First, we need to install a few libraries that we will use to read and transform the data.\n",
    "\n",
    "To do so, we'll use the `!` directive to access the shell and then use `pip` to install our dependencies as specified in the accompanying [`requirements.txt`](requirements.txt).\n",
    "\n",
    "To prevent the log messages from overflowing this notebook, we'll silence the output by directing informational messages into oblivion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c599a508-e09b-454a-bca6-2e228339ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -r requirements.txt > /dev/null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd73352-b825-41dd-92fe-8a12fb352bd1",
   "metadata": {},
   "source": [
    "\n",
    "If you find a need for other libraries, you can use a similar technique to install them directly, for instance by running `!pip install matplotlib`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b49181e-b183-46bb-b015-fff2b8769dfa",
   "metadata": {},
   "source": [
    "### Import Dependencies\n",
    "\n",
    "Now we can import the libraries we want to use explore the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3cf0246-217e-4615-97cc-3aa12b02e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import contextily as cx\n",
    "\n",
    "from glob import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628659b4-aa3d-4598-9442-c18170392a0f",
   "metadata": {},
   "source": [
    "### Find the Data\n",
    "\n",
    "In this MSD-LIVE Jupyter environment, the dataset location is stored in the `DATA_DIR` environment variable.\n",
    "\n",
    "We can again use the `!` directive to list the contents of this directory using shell commands, and we can use Python's `os.getenv()` method to get the path in code.\n",
    "\n",
    "The data is also mounted to the `/data` directory in this Jupyter environment, so you can use the File Browser to see the available files and directory structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5e263928-e1f0-49b4-9c8d-119026140c35",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!ls $DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c288cb-b8ef-4472-a35f-33e2549db012",
   "metadata": {},
   "source": [
    "### Explore the Data\n",
    "\n",
    "Now let's use `pandas` and `geopandas` to read the CSV file of weather station locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d73f73eb-761e-4dd6-ae10-18c58f512892",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read the CSV using the DATA_DIR environment variable as the path\n",
    "stations = pd.read_csv('Stations_Locations.csv')[[\n",
    "    # Select a few interesting columns\n",
    "    'Station ID', 'Site Name', 'Longitude', 'Latitude'\n",
    "]]\n",
    "\n",
    "# Convert the coordinates to a geometry column using geopandas\n",
    "stations = gpd.GeoDataFrame(\n",
    "    stations, geometry=gpd.points_from_xy(stations.Longitude, stations.Latitude)\n",
    ").set_crs('epsg:4326')\n",
    "\n",
    "# View the first few records\n",
    "stations.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a586e-4b98-4393-811f-8cdbd1d59dde",
   "metadata": {},
   "source": [
    "\n",
    "We can plot the stations locations on top of a basemap using `contextily` to get a sense for their spatial locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94b6b2-29be-487a-b305-8379f207e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproject the geometries to Web Mercator, then plot on top of a muted basemap\n",
    "ax = stations.to_crs('epsg:3857').plot(\n",
    "    figsize=(7.2, 7.2), marker='o', markersize=10,\n",
    "    color='red', edgecolor='black', linewidth=1,\n",
    ")\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "ax.set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb2fa5-9dd0-4f3c-a393-25469caf4aca",
   "metadata": {},
   "source": [
    "\n",
    "### Subset the Data\n",
    "\n",
    "Let's figure out the mean daily temperature at each station on your birthday!\n",
    "\n",
    "Update your birthday below, then we'll read in all the CSV files for 2024 and select the observations on the chosen date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57181656-3afd-4ae0-9981-bf8f89d4c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE that the dataset currently only goes through October, so you may need to fudge your birthday a little to see data...\n",
    "birthday_month = 10\n",
    "birthday_day   = 31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91d14a-8cc6-485d-a215-16685962d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in each daily file, select the date, and add the observations to a new dataframe\n",
    "\n",
    "daily_files = sorted(glob(f'{os.getenv(\"DATA_DIR\")}/data/daily/2024/*.csv'))\n",
    "\n",
    "birthday_data = []\n",
    "\n",
    "for file in daily_files:\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # ensure the dates are datetime objects\n",
    "    df['obsTimeUtc'] = pd.to_datetime(df.obsTimeUtc)\n",
    "    \n",
    "    # add observations on the chosen date to a list\n",
    "    birthday_data.append(\n",
    "        df[\n",
    "            (df.obsTimeUtc.dt.month == birthday_month) &\n",
    "            (df.obsTimeUtc.dt.day   == birthday_day)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# combine all observations from all weather stations on the chosen date into a new dataframe\n",
    "birthday_data = pd.concat(birthday_data, ignore_index=True)\n",
    "\n",
    "# View the first few records\n",
    "birthday_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c0198-cf2b-42ef-a19e-7d85395cbe69",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db8067-baf6-4481-90f7-d3137aa637f8",
   "metadata": {},
   "source": [
    "\n",
    "Let's create a histogram of all the temperatures to see the distribution of observations across weather stations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c3b91-1a9a-4aa7-816f-be6f10b27b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = birthday_data.tempAvg.hist();\n",
    "ax.set_xlabel('Average Temperature Â°C');\n",
    "ax.set_ylabel('Observations');\n",
    "ax.set_title(f'Average Temperature Observations on 2024-{str(birthday_month).zfill(2)}-{str(birthday_day).zfill(2)} across all BSEC Weather Stations');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf2a67-c6d2-4476-824c-a0b3662c7bee",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece594b3-90de-4c6d-bb6f-5dac66ba1829",
   "metadata": {},
   "source": [
    "\n",
    "### Saving the Data Subset\n",
    "\n",
    "We can also save this new dataframe and download it to a local device for later use.\n",
    "\n",
    "There are two ways to do this in the MSD-LIVE Jupyter environment.\n",
    "\n",
    "* The easy way: for small files like this one, we can just write the file into the working directory and download it using the File Browser within Jupyter.\n",
    "* For larger files (>100MB), we need to copy the file into our `scratch` directory and then use the MSD-LIVE CLI from our local device to download it.\n",
    "\n",
    "We'll demonstrate the first option here and then show you how to copy the file to your `scratch`. For more information on downloading from the `scratch` folder, check out [How to download files from your scratch directory using our CLI](https://msdlive.org/help/resources/quick-guides/using-dataset-notebooks#scratch-download).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498bfcdf-cf01-4e64-a029-6d140abc2cea",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd22314-0301-4c15-bf82-e5d325044321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the birthday subset dataframe to the current directory\n",
    "birthday_data.to_csv('birthday_weather_station_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8522146-c334-4a4e-a80d-a84c89c4377b",
   "metadata": {},
   "source": [
    "\n",
    "You should now be able to see the data in the file explorer at [/notebooks/birthday_weather_station_data.csv](birthday_weather_station_data.csv). Right click this file in the File Browser and select \"Download\" to copy the file locally.\n",
    "\n",
    "If the file was too big to download directly, you could first right click it and select \"Copy to Scratch\", and then follow the directions linked above to use the MSD-LIVE CLI to download from your `scratch` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51773782-56ac-4657-a455-23d42bdc2875",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78785f4-2e7d-4a57-b496-cefc5faf31e7",
   "metadata": {},
   "source": [
    "Thanks for following along; you should now be empowered to explore the data for your own purposes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4e8d5-da1a-41d3-bf76-fe53e4fdff01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
