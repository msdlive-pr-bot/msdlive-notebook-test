{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "2868915f-734d-4c8f-a3cb-368c2a674c86",
   "metadata": {},
   "source": [
    "# Explore Weather Data from BSEC Weather Stations\n",
    "\n",
    "Welcome! This notebook will demonstrate how to use the MSD-LIVE data exploration service to visualize, transform, and download a subset of data collected from weather stations around the Baltimore area.\n",
    "\n",
    "You can find the original dataset record at [https://doi.org/10.57931/2476281](https://doi.org/10.57931/2476281).\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82e52864-dba3-4f67-98f6-cb8c6a4a29a4",
   "metadata": {},
   "source": [
    "### Install Dependencies\n",
    "\n",
    "First, we need to install a few libraries that we will use to read and transform the data.\n",
    "\n",
    "To do so, we'll use the `!` directive to access the shell and then use `pip` to install our dependencies as specified in the accompanying [`requirements.txt`](requirements.txt).\n",
    "\n",
    "To prevent the log messages from overflowing this notebook, we'll silence the output by directing informational messages into oblivion.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c599a508-e09b-454a-bca6-2e228339ade9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "!pip install -r requirements.txt > /dev/null\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ccd73352-b825-41dd-92fe-8a12fb352bd1",
   "metadata": {},
   "source": [
    "\n",
    "If you find a need for other libraries, you can use a similar technique to install them directly, for instance by running `!pip install matplotlib`\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b49181e-b183-46bb-b015-fff2b8769dfa",
   "metadata": {},
   "source": [
    "### Import Dependencies\n",
    "\n",
    "Now we can import the libraries we want to use explore the dataset.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "d3cf0246-217e-4615-97cc-3aa12b02e6e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import geopandas as gpd\n",
    "import pandas as pd\n",
    "import contextily as cx\n",
    "\n",
    "from glob import glob\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "628659b4-aa3d-4598-9442-c18170392a0f",
   "metadata": {},
   "source": [
    "### Find the Data\n",
    "\n",
    "In this MSD-LIVE Jupyter environment, the dataset location is stored in the `DATA_DIR` environment variable.\n",
    "\n",
    "We can again use the `!` directive to list the contents of this directory using shell commands, and we can use Python's `os.getenv()` method to get the path in code.\n",
    "\n",
    "The data is also mounted to the `/data` directory in this Jupyter environment, so you can use the File Browser to see the available files and directory structure.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "5e263928-e1f0-49b4-9c8d-119026140c35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data  documents\n"
     ]
    }
   ],
   "source": [
    "\n",
    "!ls $DATA_DIR\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "73c288cb-b8ef-4472-a35f-33e2549db012",
   "metadata": {},
   "source": [
    "### Explore the Data\n",
    "\n",
    "Now let's use `pandas` and `geopandas` to read the CSV file of weather station locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d73f73eb-761e-4dd6-ae10-18c58f512892",
   "metadata": {},
   "outputs": [
    {
     "ename": "FileNotFoundError",
     "evalue": "[Errno 2] No such file or directory: '/data/Stations_Locations.csv'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[4], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m# Read the CSV using the DATA_DIR environment variable as the path\u001b[39;00m\n\u001b[0;32m----> 2\u001b[0m stations \u001b[38;5;241m=\u001b[39m \u001b[43mpd\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mread_csv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43mf\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[43mos\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgetenv\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mDATA_DIR\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[38;5;124;43m/Stations_Locations.csv\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m[[\n\u001b[1;32m      3\u001b[0m     \u001b[38;5;66;03m# Select a few interesting columns\u001b[39;00m\n\u001b[1;32m      4\u001b[0m     \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mStation ID\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mSite Name\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLongitude\u001b[39m\u001b[38;5;124m'\u001b[39m, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mLatitude\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m      5\u001b[0m ]]\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Convert the coordinates to a geometry column using geopandas\u001b[39;00m\n\u001b[1;32m      8\u001b[0m stations \u001b[38;5;241m=\u001b[39m gpd\u001b[38;5;241m.\u001b[39mGeoDataFrame(\n\u001b[1;32m      9\u001b[0m     stations, geometry\u001b[38;5;241m=\u001b[39mgpd\u001b[38;5;241m.\u001b[39mpoints_from_xy(stations\u001b[38;5;241m.\u001b[39mLongitude, stations\u001b[38;5;241m.\u001b[39mLatitude)\n\u001b[1;32m     10\u001b[0m )\u001b[38;5;241m.\u001b[39mset_crs(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mepsg:4326\u001b[39m\u001b[38;5;124m'\u001b[39m)\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1026\u001b[0m, in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1013\u001b[0m kwds_defaults \u001b[38;5;241m=\u001b[39m _refine_defaults_read(\n\u001b[1;32m   1014\u001b[0m     dialect,\n\u001b[1;32m   1015\u001b[0m     delimiter,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1022\u001b[0m     dtype_backend\u001b[38;5;241m=\u001b[39mdtype_backend,\n\u001b[1;32m   1023\u001b[0m )\n\u001b[1;32m   1024\u001b[0m kwds\u001b[38;5;241m.\u001b[39mupdate(kwds_defaults)\n\u001b[0;32m-> 1026\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:620\u001b[0m, in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    617\u001b[0m _validate_names(kwds\u001b[38;5;241m.\u001b[39mget(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mnames\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;28;01mNone\u001b[39;00m))\n\u001b[1;32m    619\u001b[0m \u001b[38;5;66;03m# Create the parser.\u001b[39;00m\n\u001b[0;32m--> 620\u001b[0m parser \u001b[38;5;241m=\u001b[39m \u001b[43mTextFileReader\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfilepath_or_buffer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwds\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    622\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m chunksize \u001b[38;5;129;01mor\u001b[39;00m iterator:\n\u001b[1;32m    623\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m parser\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1620\u001b[0m, in \u001b[0;36mTextFileReader.__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1617\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39moptions[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m kwds[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhas_index_names\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n\u001b[1;32m   1619\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles: IOHandles \u001b[38;5;241m|\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[0;32m-> 1620\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_engine \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_make_engine\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mengine\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/parsers/readers.py:1880\u001b[0m, in \u001b[0;36mTextFileReader._make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[1;32m   1879\u001b[0m         mode \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m-> 1880\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;241m=\u001b[39m \u001b[43mget_handle\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1881\u001b[0m \u001b[43m    \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1882\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1883\u001b[0m \u001b[43m    \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1884\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompression\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mcompression\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1885\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmemory_map\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmemory_map\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1886\u001b[0m \u001b[43m    \u001b[49m\u001b[43mis_text\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mis_text\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1887\u001b[0m \u001b[43m    \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mencoding_errors\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstrict\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1888\u001b[0m \u001b[43m    \u001b[49m\u001b[43mstorage_options\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptions\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mstorage_options\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1889\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1890\u001b[0m \u001b[38;5;28;01massert\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m   1891\u001b[0m f \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhandles\u001b[38;5;241m.\u001b[39mhandle\n",
      "File \u001b[0;32m/opt/conda/lib/python3.11/site-packages/pandas/io/common.py:873\u001b[0m, in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    868\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(handle, \u001b[38;5;28mstr\u001b[39m):\n\u001b[1;32m    869\u001b[0m     \u001b[38;5;66;03m# Check whether the filename is to be opened in binary mode.\u001b[39;00m\n\u001b[1;32m    870\u001b[0m     \u001b[38;5;66;03m# Binary mode does not support 'encoding' and 'newline'.\u001b[39;00m\n\u001b[1;32m    871\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mencoding \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mb\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m ioargs\u001b[38;5;241m.\u001b[39mmode:\n\u001b[1;32m    872\u001b[0m         \u001b[38;5;66;03m# Encoding\u001b[39;00m\n\u001b[0;32m--> 873\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mopen\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[1;32m    874\u001b[0m \u001b[43m            \u001b[49m\u001b[43mhandle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    875\u001b[0m \u001b[43m            \u001b[49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    876\u001b[0m \u001b[43m            \u001b[49m\u001b[43mencoding\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mioargs\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mencoding\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    877\u001b[0m \u001b[43m            \u001b[49m\u001b[43merrors\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43merrors\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    878\u001b[0m \u001b[43m            \u001b[49m\u001b[43mnewline\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m    879\u001b[0m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    880\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[1;32m    881\u001b[0m         \u001b[38;5;66;03m# Binary mode\u001b[39;00m\n\u001b[1;32m    882\u001b[0m         handle \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mopen\u001b[39m(handle, ioargs\u001b[38;5;241m.\u001b[39mmode)\n",
      "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: '/data/Stations_Locations.csv'"
     ]
    }
   ],
   "source": [
    "\n",
    "# Read the CSV using the DATA_DIR environment variable as the path\n",
    "stations = pd.read_csv(f'{os.getenv(\"DATA_DIR\")}/Stations_Locations.csv')[[\n",
    "    # Select a few interesting columns\n",
    "    'Station ID', 'Site Name', 'Longitude', 'Latitude'\n",
    "]]\n",
    "\n",
    "# Convert the coordinates to a geometry column using geopandas\n",
    "stations = gpd.GeoDataFrame(\n",
    "    stations, geometry=gpd.points_from_xy(stations.Longitude, stations.Latitude)\n",
    ").set_crs('epsg:4326')\n",
    "\n",
    "# View the first few records\n",
    "stations.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8a586e-4b98-4393-811f-8cdbd1d59dde",
   "metadata": {},
   "source": [
    "\n",
    "We can plot the stations locations on top of a basemap using `contextily` to get a sense for their spatial locations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3c94b6b2-29be-487a-b305-8379f207e9df",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Reproject the geometries to Web Mercator, then plot on top of a muted basemap\n",
    "ax = stations.to_crs('epsg:3857').plot(\n",
    "    figsize=(7.2, 7.2), marker='o', markersize=10,\n",
    "    color='red', edgecolor='black', linewidth=1,\n",
    ")\n",
    "cx.add_basemap(ax, source=cx.providers.CartoDB.Positron)\n",
    "ax.set_axis_off()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfb2fa5-9dd0-4f3c-a393-25469caf4aca",
   "metadata": {},
   "source": [
    "\n",
    "### Subset the Data\n",
    "\n",
    "Let's figure out the mean daily temperature at each station on your birthday!\n",
    "\n",
    "Update your birthday below, then we'll read in all the CSV files for 2024 and select the observations on the chosen date.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "57181656-3afd-4ae0-9981-bf8f89d4c465",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# NOTE that the dataset currently only goes through October, so you may need to fudge your birthday a little to see data...\n",
    "birthday_month = 10\n",
    "birthday_day   = 31\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea91d14a-8cc6-485d-a215-16685962d7c3",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Read in each daily file, select the date, and add the observations to a new dataframe\n",
    "\n",
    "daily_files = sorted(glob(f'{os.getenv(\"DATA_DIR\")}/daily/2024/*.csv'))\n",
    "\n",
    "birthday_data = []\n",
    "\n",
    "for file in daily_files:\n",
    "    \n",
    "    df = pd.read_csv(file)\n",
    "    \n",
    "    # ensure the dates are datetime objects\n",
    "    df['obsTimeUtc'] = pd.to_datetime(df.obsTimeUtc)\n",
    "    \n",
    "    # add observations on the chosen date to a list\n",
    "    birthday_data.append(\n",
    "        df[\n",
    "            (df.obsTimeUtc.dt.month == birthday_month) &\n",
    "            (df.obsTimeUtc.dt.day   == birthday_day)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "# combine all observations from all weather stations on the chosen date into a new dataframe\n",
    "birthday_data = pd.concat(birthday_data, ignore_index=True)\n",
    "\n",
    "# View the first few records\n",
    "birthday_data.head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f35c0198-cf2b-42ef-a19e-7d85395cbe69",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "66db8067-baf6-4481-90f7-d3137aa637f8",
   "metadata": {},
   "source": [
    "\n",
    "Let's create a histogram of all the temperatures to see the distribution of observations across weather stations:\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a37c3b91-1a9a-4aa7-816f-be6f10b27b11",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "ax = birthday_data.tempAvg.hist();\n",
    "ax.set_xlabel('Average Temperature Â°C');\n",
    "ax.set_ylabel('Observations');\n",
    "ax.set_title(f'Average Temperature Observations on 2024-{str(birthday_month).zfill(2)}-{str(birthday_day).zfill(2)} across all BSEC Weather Stations');\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8cf2a67-c6d2-4476-824c-a0b3662c7bee",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ece594b3-90de-4c6d-bb6f-5dac66ba1829",
   "metadata": {},
   "source": [
    "\n",
    "### Saving the Data Subset\n",
    "\n",
    "We can also save this new dataframe and download it to a local device for later use.\n",
    "\n",
    "There are two ways to do this in the MSD-LIVE Jupyter environment.\n",
    "\n",
    "* The easy way: for small files like this one, we can just write the file into the working directory and download it using the File Browser within Jupyter.\n",
    "* For larger files (>100MB), we need to copy the file into our `scratch` directory and then use the MSD-LIVE CLI from our local device to download it.\n",
    "\n",
    "We'll demonstrate the first option here and then show you how to copy the file to your `scratch`. For more information on downloading from the `scratch` folder, check out [How to download files from your scratch directory using our CLI](https://msdlive.org/help/resources/quick-guides/using-dataset-notebooks#scratch-download).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "498bfcdf-cf01-4e64-a029-6d140abc2cea",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cd22314-0301-4c15-bf82-e5d325044321",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Save the birthday subset dataframe to the current directory\n",
    "birthday_data.to_csv('birthday_weather_station_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8522146-c334-4a4e-a80d-a84c89c4377b",
   "metadata": {},
   "source": [
    "\n",
    "You should now be able to see the data in the file explorer at [/notebooks/birthday_weather_station_data.csv](birthday_weather_station_data.csv). Right click this file in the File Browser and select \"Download\" to copy the file locally.\n",
    "\n",
    "If the file was too big to download directly, you could first right click it and select \"Copy to Scratch\", and then follow the directions linked above to use the MSD-LIVE CLI to download from your `scratch` directory.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "51773782-56ac-4657-a455-23d42bdc2875",
   "metadata": {},
   "source": [
    "<br/>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a78785f4-2e7d-4a57-b496-cefc5faf31e7",
   "metadata": {},
   "source": [
    "Thanks for following along; you should now be empowered to explore the data for your own purposes!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a4e8d5-da1a-41d3-bf76-fe53e4fdff01",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
